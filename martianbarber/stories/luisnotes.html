<!DOCTYPE html>
<html>
	<head>
		<title> Hayden Gemeinhardt </title>
		<link rel="stylesheet" type="text/css" href="../../style.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i,900,900i">
		<style>
		h1 {font: 700 2.0rem/1.2 "Roboto";}
		h2 {font: 700 1.5rem/1.2 "Roboto";} 
		h3 {font: 700 1.0rem/1.2 "Roboto";}
		title {font: 700 3.0rem/1.2 "Roboto";}


		</style>
	</head>

	<body>
		<div style="background-image: url('mars2.jpg')" class="container">
			<div class="header">
				<div class="headercontent"></div>
			</div>
			<div class="content">
				<div class="title" style="text-align:center"></div>
				<div class="row">
					<div class="column60">
						<div class="card">
							<div class="prose">
								<a href="#" onClick="history.go(-1);return true;">Back To Catalog</a>
								<h3 style="text-align: right">Page 1</h3>
								<h1 style="text-align: center; font-size: 50px">The Martian Barber</h1>
								<h2 style="text-align: center">By Hayden Gemeinhardt</h2><br>
								<h1 style="text-align: center">Luis's Notes</h1><br>
								

<p><i>Purpose: Part 2 of last chapter, not necesary to read. Just having some fun with more "academic" writing.</i></p><p>----------------------------------------------------------------------------------</p>
<p>Mars was no more than a ruby moon in a glittered sky the night my mind determined itself a machine, that Cartesian Dualism was no more than a feeble philosophical term to explain its technological counterpart: <b>black box.</b></p>
<p>When we send inputs to our machines and accept their output as rational despite coming from irrational standpoints, when we understand why a computer does something without knowing how the computer comes to its conclusion, it tells us no more than knowing how a computer comes to its conclusion but not understanding why the computer does it.</p>
<p>It is AI’s Heisenberg Principle, or as I like to call it, the Luis Certainty principle(?), a very simple principle named after yours truly as I have found no one else to claim it, though I am sure they have and feel as unfortunate as me to ponder it, as it has brought as much headache to me as Heisenberg to Einstein.</p>
<p>However, it is almost antithetical to Heisenberg’s reasoning, that while the position and velocity of an object cannot be measured at the same time, the how and why of an algorithm can only be measured at the same time, as they are one in the same. It’s a principle of equality, that one cannot be greater than or less than one. The why cannot be greater or less meaningful than the how.</p>
<p>A computer arrives at its results when enough electric voltage has been applied to the gate near a FET’s boron-doped silicon to allow the electrons flowing into the phosphorus-doped silicon on one side to overcome the repulsion of depletion zoned formed by the neighboring, opposing silicons and travel to its twin on the other side. This manipulation of the properties of a crystal creates a switch, where the “closed-switch” flow represents a 1 and the “open switch” barrier represents a 0. At least, this was the case at the time of my ruby moon.</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 2</h3>
<p>Further exploitation of this property results in logic gates. By connecting the gates of an nMOS transistor and a pMOS transistor (where the silicon types are reversed) to the same input, the source of the nMOS to ground and the source of the pMOS to voltage, and taking the output from their combined drains, one can create an inverter circuit, so the output will always be opposite to that of the input. A couple of more transistors and you can create the universal NAND and NOR gates. Put these gates side-by-side, and you get a streamline of 1s and 0s, each capable of changing with response to a change in their individual inputs to calculate the most rigorous of Boolean equations.</p>
<p>Our artificial intelligence does no more than modify its seemingly infinite strand of 1s and 0s. To our eyes, from a god-like perspective, we program in an interpreted programming language that progressively gets translated to assembly language, machine language, and finally binary code. But our god-like perspective is no different than a machine’s perspective of us. Our words are formed at a base foundation on the neuron level, much like a binary level, and translated upward into higher level languages. <strike>Of course, neurons are only comparable in the slightest sense, as they contain dendrites and axons and all other complexities of a living cell, but that misses the point.</strike></p>
<p>Why do I go through the trouble of explaining this? Because most believe humans are different than machines, when in reality, human and machine are homogeneous, much like men and women, Africans and Europeans, or Buddhists and Muslims. The Turing test is a test of the past, much like the Jim Crow literacy tests, designed only to make one group feel superior to the other. And much like I do not believe humans are superior to computers, I do not believe computers are superior to humans.</p>
<p><strike>I expect for my opinions to be shut down as they have in the past.</strike> For many, many decades, scientists have argued our mind vastly incomparable to machine. But science has always been about pursuing ideas despite, ironically, what other scientists ridicule. </p>
<p>The alternative, from one side, is to always view AI as a black box as we do not understand the whys/hows of its inner-workings. This is not because of our inability to do so; given a long enough time, we can break the bits apart one by one, map them, and reassemble them like a spaceship. It’s a lack of belief in any significant reason to do so.</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 3</h3>
<p>And much like we have seen AI as a black box, we have seen the human intuition as a spirit, separate from matter, that the mind thinks and does not occupy space while matter occupies space but does not think. While modern minds say they don’t believe this to be the case--and shout their atheism from the tops of roofs as medieval philosophers would do with Christianity--they continue to push the idea the mind is too different from a computer to compare. I cannot think of another reason they would say that apart from a lack of understanding of the human mind. For the further technology advances, we simulate more complex aspects of the universe. Neurochips and gliachips already simulate foundational components of the human mind. The whole of the human mind is at the peak of that mountain and there is no intelligent reason one could give me to prove it otherwise; no one has provided one yet, and if it held a foundational truth, then one would need no more than to lay it out instead of arguing baseless points. On the contrary, if in this process we discover meaning behind the physical brain that contradicts all these presumptions, then it would be the discovery of the millennia in of itself, and one I would be more than happy of settling on.</p>
<p>Building on that foundation, I believe if we can work out the algorithms behind the human mind, much like we have the ability to work out the algorithms behind an AI’s reasoning... <strike>a world of possibilities open up.</strike></p>
<p>----</p>
<p>My first conjecture is that consciousness is scalable. Meaning that, as much as it can be hindered, it can be enhanced.</p>
<p>Although we have yet to create a definition on consciousness or to put it into words, we have a conceptual understanding. If there is one thing in the world we know, it’s that we exist in some conscious mind, ergo “I think, therefore I exist”. Furthermore, we can be almost certain the rocks beneath our feet do not have that same property. So we at least have two ends of a pole. But to show this is an axis and not merely two sides of a coin, observe animals around you. A major difference between (at least most) animals and humans is the Default Node Network, the ability for self-reflection and meta-level thinking as we exist in the world, to see if we can improve ourselves to increase our success. A deer will not have the capability of seeing itself as stupid the same way we can view ourselves as stupid. Yet, it is widely accepted in psychology, as represented with the landmark Cambridge Declaration on Consciousness, that our understanding of consciousness is not a human-specific trait. Furthermore, I believe it to be dull to think humans have peaked in terms of consciousness considering we can’t put it into words as we can with all other things.</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 4</h3>
<p>Building on that conjecture, I then propose six possible scenarios that can occur when bringing consciousness to machines:</p>
<ol>
<li>Consciousness is possible only with the structure of a biological mind</li>
<li>Consciousness is better achievable with the structure of a biological mind</li>
<li>Consciousness is equally achievable with the structure of a biological mind and a computer</li>
<li>Consciousness is better achievable with the structure of a computer</li>
<li>Consciousness is possible only with the structure of a computer</li>
<li>Consciousness isn’t possible</li>
</ol>
<p>Regarding part 6, this is false as consciousness is the fundamental aspect of our existence, the one thing we know to be true. The same can be said for part 5.</p>
<p>As explained previously, I do not believe part 1 to be true either, although if we find this to be true, it will be a landmark discovery that will shake our society to the bones. Furthermore, the only way to explore whether the remaining parts will be our future is to rigorously disprove path 1, to map the algorithms of the human mind and implement them into a computer. </p>
<p>As for part 3, the least exciting of the possible scenarios, yet the second most commonly believed one outside of part 1, I believe it will have the same consequences and benefits as I will get to in part 4, as the only advantage humans have over computers is our consciousness and meaning. I do not know anyone who would like to rid of themselves of consciousness to become a computer outside of those who, unfortunately, also rid themselves of capacity to live in due time.</p>
<p>If part 2 is true, then logically, beyond implementing computers into our brain (for the time being) to increase our capacity for calculation, we should research ways to expand our mind with artificial, biological minds to gain the higher level of consciousness. This is not the same as a computer as computers are electronic devices, not biological devices. Some may view part 2 as a relief, subverting the expectation at some point AI will take over if AI will depend on us for consciousness, though that can relate to nightmare scenarios in of itself.</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 5</h3>
<p>If part 4 is true, then humans serve no need to exist biologically given our goals to advance as far as possible. However, shall we find a way to implement computers into our mind, this next step in consciousness will have unforeseen affects. This also raises the question if two consciousnesses can be connected. Specifically, that of a human and of a computer. It also raises the Ship of Theseus from its harbor. If we can fully replicate the mind of a human, say of yours truly, into a computer as would be capable under the assumptions raised earlier, would I still be me? This may be an important question to ask before stepping into a deadly river with both feet hoping where you end up will be better than where you started. These are questions I dread to find an answer, though perhaps the higher state of consciousness one will achieve could bring the answers to us, and I am more than willing to wait to find out. </p>
<p>Paths 2 and 4 bring very distinct and differing options for mankind’s interaction with computers. In one scenario, we keep them merely as slaves as a car is to a man; the other, we become slave to them as a man is slave to his car. Out of necessity to advance. And soon abandon all biological functioning for intelligence, immortality, and all other dangers that come with it.</p>
<p>Yet, only long after we have surpassed path 1 will paths 2 and 4 aggressively split. The two paths blend where man and machine are slave to each other equally, but as friends in a Nash equilibrium without incentive to defer from the main path until the main path splits, and the chosen path will be up to the universe itself to decide.</p>
<p>Because we are friends in this equilibrium until we can achieve this goal, we must put the horse before the cart. We must befriend our technological counter parts to an extreme level. If a program takes one hour to code and four hours to debug, the communication between man and computer is at an extreme inefficiency. This is due to our inability to finish bridging the gap where our two languages, neurons and transistors, meet at a higher level, like a bridge whose halves are built on different elevations. Surely there is no need to decrease the time from 5 hours to 1 hour if it takes 20 hours to accomplish. But if the path to higher consciousness in on the other side of that bridge, humans will want the bridge between us to connect equally, and vice versa for machine. It is in in both of our interests to connect that bridge out of the possibility for the striking of gold to be on the other side.</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 6</h3>
<p>And for those that believe the efficiency will only ever be on our side, who do not see any risk at all, you should understand that the fastest horse is on the other side of that bridge for the time being, and the cart of higher consciousness is much further away.</p>
<p>----</p>
<p>The first part of my process is to give computers the ability to interpret the algorithms behind our mind. Substantial progress has already been made in this respect, as we can replace limbs with artificial counterparts and control machines with our mind, but it’s to a limited extent. I expect a counter will be raised that the limitation is in our ability to interpret the machines response, that we cannot have the machine send signals back to our brain for touch as it is a one lane road. However, that is narrow-scoped.</p>
<p>Computers do not understand why we want to move the arm, only that we do. This does not have to be. According to the Luis Certainty Principle(?), the why is the same as the how, and the how can be mapped. Why only measure the neurons that move the arm when we can also measure the neurons that decide why the arm needs to be moved? <strike>The latter is more difficult, no doubt, But, as John F. Kennedy put it, “We choose to go to the moon in this decade and do the other things. Not because they are easy, but because they are hard.” </strike></p>
<p>If we want to fully communicate with computers, then computers cannot read the brain in small bits and pieces, but must read it as a whole. Much like you don’t know why a fellow man believes what he believes until you’ve seen the life he has lived, or as Descartes put it, “the diversity of our views does not result from the fact that some people are more reasonable than others, but simply from the fact that we guide our thoughts along different paths than others.” It is not enough to know the end of the path a man is on, but to know the path he took. It’s the foundation of human-to-human interaction, and thus should be the same for human-to-machine interaction.</p>
<p>add transition</p>
<p>The second part of the process is to give humans the ability to interpret the algorithms behind the computer. This is as basic as <b>the principle of transparency in AI. If one is to be judged guilty by an AI, surely one would want to know why/how it came to that conclusion.</b></p>
<p>&ltfix&gt</p>
<p>I find this part to be the more difficult one (hence why it is the second part) as humans conceptualize things much more than the logical trial/error of computers. If a computer were to give us a book on the path it took, it would be helpful, but take too long to create the concept in our mind. On the other hand, using a symbol-based communication eliminates the redundancy of spoken communication, but much of that redundancy is necessary to understand context and meaning. This is increasingly important as, most of the time, the paths AI takes seem alien to us, and using a picture that is worth a thousand words may prove counterintuitive (though note how a pre-existing understanding of that picture may save a thousand words).</p>
<p>&lt/fix&gt</p>
</div></div>
<div class="card"><div class="prose">
<h3 style="text-align: right">Page 7</h3>
<p>It’s important to note I label these as parts, not as steps. These two projects will coincide simultaneously, together as one step. The second step is where the paths split, to combine the two mappings and find out which is more efficient at what. Now that each knows that path they took, they can debate about which is better. My hopes is this debate will be short, to stray away from path 3 (wtf is path 3 again?).</p>
<p>---</p>
<p>Doctor, when I said this may be the last time we see each other, I didn’t mean I may not leave. That is set in stone. I meant I still have hopes you may join us.</p>
								<a href="#" onClick="history.go(-1);return true;">Back To Catalog</a>
							</div>
						</div>
					</div>
				</div>
				<div style="padding-bottom:60px"></div>
			</div>
			<div class="footer">
				Copyright &copy; 2020 Hayden Gemeinhardt
			</div>
		</div>
	</body>

</html>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>

<script>
$(document).ready(function(){
        $(".headercontent").load("../../ffolderheadercontent.txt");
    ;
});
</script>